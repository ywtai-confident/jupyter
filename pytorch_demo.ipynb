{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed61bcac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files (x86)\\anaconda3\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: Could not find module 'D:\\Program Files (x86)\\anaconda3\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data_utils\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb416197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# strcmp strcpy strstr strchr strtok strcat memcpy memmove restrict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19c11038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载fashion-mnist数据集\n",
    "train_transform = transforms.Compose([\n",
    "#     transforms.RandomResizedCrop((28, 28)),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.RandomVerticalFlip(),\n",
    "#     transforms.RandomRotation(90),\n",
    "#     transforms.RandomGrayscale(0.1), # 0.1的概率转换为灰度图\n",
    "#     transforms.ColorJitter(0.3, 0.3, 0.3, 0.3),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_data = datasets.FashionMNIST(root='fashion-mnist', train=True, \n",
    "                                   transform=train_transform,\n",
    "                                   download=False)\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "#     transforms.Resize((28, 28)),\n",
    "#     transforms.Normalize((0.49, 0.48, 0.44), (0.2, 0.22, 0.21)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "test_data = datasets.FashionMNIST(root='fashion-mnist', train=False, \n",
    "                                  transform=test_transform, download=False)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = data_utils.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = data_utils.DataLoader(dataset=test_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84bc2b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 32, kernel_size=5, padding=1),\n",
    "            torch.nn.BatchNorm2d(32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.fc = torch.nn.Linear(14 * 14 * 32, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        out = self.fc(out)\n",
    "        out = F.log_softmax(out, dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8b5eb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channel, out_channel, stride=1):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.layer = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channel, out_channel, kernel_size=3, stride=stride, padding=1),\n",
    "            torch.nn.BatchNorm2d(out_channel),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(out_channel, out_channel, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.BatchNorm2d(out_channel)\n",
    "        )\n",
    "        \n",
    "        self.shortcut = torch.nn.Sequential()\n",
    "        if in_channel != out_channel or stride > 1:\n",
    "            self.shortcut = torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(in_channel, out_channel, \n",
    "                                kernel_size=3, stride=stride, padding=1),\n",
    "                torch.nn.BatchNorm2d(out_channel)\n",
    "            )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out1 = self.layer(x)\n",
    "        out2 = self.shortcut(x)\n",
    "        out = out1 + out2\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            torch.nn.BatchNorm2d(32),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        self.layer1 = self.make_layer(ResBlock, 32, 64, 2, 2)\n",
    "        self.layer2 = self.make_layer(ResBlock, 64, 128, 2, 2)\n",
    "        self.layer3 = self.make_layer(ResBlock, 128, 256, 2, 2)\n",
    "        self.layer4 = self.make_layer(ResBlock, 256, 512, 2, 2)\n",
    "        self.mp = torch.nn.MaxPool2d(2)\n",
    "        self.fc = torch.nn.Linear(512, 10)\n",
    "    \n",
    "    @staticmethod\n",
    "    def make_layer(block, in_channel, out_channel, stride, num_block):\n",
    "        layers_list = []\n",
    "        temp_channel = in_channel\n",
    "        for i in range(num_block):\n",
    "            in_stride = stride if i == 0 else 1\n",
    "            layers_list.append(block(temp_channel, out_channel, in_stride))\n",
    "            temp_channel = out_channel\n",
    "        return torch.nn.Sequential(*layers_list)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.mp(out)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        out = self.fc(out)\n",
    "        out = F.log_softmax(out, dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9caa8627",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobileNet(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MobileNet, self).__init__()\n",
    "        self.conv = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            torch.nn.BatchNorm2d(32),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        self.conv_dpw1 = self.conv_dw(32, 32, 1)\n",
    "        self.conv_dpw2 = self.conv_dw(32, 64, 2)\n",
    "        \n",
    "        self.conv_dpw3 = self.conv_dw(64, 64, 1)\n",
    "        self.conv_dpw4 = self.conv_dw(64, 128, 2)\n",
    "        \n",
    "        self.conv_dpw5 = self.conv_dw(128, 128, 1)\n",
    "        self.conv_dpw6 = self.conv_dw(128, 256, 2)\n",
    "        \n",
    "        self.conv_dpw7 = self.conv_dw(256, 256, 1)\n",
    "        self.conv_dpw8 = self.conv_dw(256, 512, 2)\n",
    "        \n",
    "        self.fc = torch.nn.Linear(512, 10)\n",
    "    \n",
    "    @staticmethod\n",
    "    def conv_dw(in_channel, out_channel, stride):\n",
    "        return torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channel, in_channel, kernel_size=3, \n",
    "                            stride=stride, padding=1, groups=in_channel),\n",
    "            torch.nn.BatchNorm2d(in_channel),\n",
    "            torch.nn.ReLU(),\n",
    "            \n",
    "            torch.nn.Conv2d(in_channel, out_channel, kernel_size=1),\n",
    "            torch.nn.BatchNorm2d(out_channel),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.conv_dpw1(out)\n",
    "        out = self.conv_dpw2(out)\n",
    "        out = self.conv_dpw3(out)\n",
    "        out = self.conv_dpw4(out)\n",
    "        out = self.conv_dpw5(out)\n",
    "        out = self.conv_dpw6(out)\n",
    "        out = self.conv_dpw7(out)\n",
    "        out = self.conv_dpw8(out)\n",
    "        out = F.avg_pool2d(out, 2)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23300151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CBR(in_channel, out_channel, kernel_size, stride=1):\n",
    "    return torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(in_channel, out_channel, \n",
    "                        kernel_size=kernel_size, stride=stride, \n",
    "                        padding=kernel_size // 2),\n",
    "        torch.nn.BatchNorm2d(out_channel),\n",
    "        torch.nn.ReLU()\n",
    "    )\n",
    "\n",
    "class BaseInception(torch.nn.Module):\n",
    "    def __init__(self, in_channel, out_channel_list):\n",
    "        super(BaseInception, self).__init__()\n",
    "        self.branch1 = CBR(in_channel, out_channel_list[0], 1)\n",
    "        self.branch2 = torch.nn.Sequential(\n",
    "            CBR(in_channel, out_channel_list[1] // 2, 1),\n",
    "            CBR(out_channel_list[1] // 2, out_channel_list[1], 3)\n",
    "        )\n",
    "        self.branch3 = torch.nn.Sequential(\n",
    "            CBR(in_channel, out_channel_list[2] // 2, 1),\n",
    "            CBR(out_channel_list[2] // 2, out_channel_list[2], 3),\n",
    "            CBR(out_channel_list[2], out_channel_list[2], 3)\n",
    "        )\n",
    "        self.branch4 = torch.nn.Sequential(\n",
    "            torch.nn.MaxPool2d(3, stride=1, padding=1),\n",
    "            CBR(in_channel, out_channel_list[3], 1),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out1 = self.branch1(x)\n",
    "        out2 = self.branch2(x)\n",
    "        out3 = self.branch3(x)\n",
    "        out4 = self.branch4(x)\n",
    "        out = torch.cat([out1, out2, out3, out4], dim=1)\n",
    "        return out\n",
    "\n",
    "class InceptionNet(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(InceptionNet, self).__init__()\n",
    "        self.block1 = torch.nn.Sequential(\n",
    "            CBR(1, 32, 3, 1), CBR(32, 64, 3, 2)\n",
    "        )\n",
    "        self.block2 = torch.nn.Sequential(\n",
    "            BaseInception(64, [32, 64, 16, 16]),\n",
    "            CBR(128, 256, 3, 2)\n",
    "        )\n",
    "        self.block3 = torch.nn.Sequential(\n",
    "            BaseInception(256, [64, 128, 32, 32]),\n",
    "            CBR(256, 512, 3, 2)\n",
    "        )\n",
    "        self.avg_pool = torch.nn.AvgPool2d(2)\n",
    "        self.fc = torch.nn.Linear(2*2*512, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.block1(x)\n",
    "        out = self.block2(out)\n",
    "        out = self.block3(out)\n",
    "        out = self.avg_pool(out)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0724a852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# cnn = InceptionNet()\n",
    "# cnn = cnn.to(device)\n",
    "# # loss\n",
    "# loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer = torch.optim.Adam(cnn.parameters(), lr=0.01)\n",
    "\n",
    "# # 每经过step_size个epoch，学习率会衰减为之前的gamma倍\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.9)\n",
    "\n",
    "# if not os.path.exists('log'):\n",
    "#     os.mkdir('log')\n",
    "# writer = SummaryWriter('log')\n",
    "\n",
    "# step_train = 0\n",
    "# step_test = 0\n",
    "# for epoch in range(10):\n",
    "#     for i, im_data in enumerate(train_loader):\n",
    "#         images, labels = im_data\n",
    "#         images = images.to(device)\n",
    "#         labels = labels.to(device)\n",
    "#         outputs = cnn(images)\n",
    "#         loss = loss_func(outputs, labels)\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         print(f'epoch is {epoch+1}, ite is {i}/{len(train_data) // batch_size}, loss is {loss.item()}')\n",
    "#         _, pred = outputs.max(1)\n",
    "#         correct = torch.sum(pred == labels).item()\n",
    "#         print('train correct', 100 * correct / batch_size)\n",
    "#         writer.add_scalar('train loss', loss.item(), global_step=step_train)\n",
    "#         writer.add_scalar('train correct', 100 * correct / batch_size, global_step=step_train)\n",
    "# #         im = torchvision.utils.make_grid(images)\n",
    "# #         writer.add_image('train im', im, global_step=step_train)\n",
    "#         step_train += 1\n",
    "# #         del images, labels\n",
    "# #         gc.collect()\n",
    "# #         torch.cuda.empty_cache()\n",
    "        \n",
    "#     # save models\n",
    "#     if not os.path.exists('models'):\n",
    "#         os.makedirs('models')\n",
    "#     torch.save(cnn.state_dict(), fr'models\\test_{epoch}.pth')\n",
    "#     scheduler.step()\n",
    "# #     print('lr is: ', optimizer.state_dict()['param_groups'][0]['lr'])\n",
    "    \n",
    "#     loss, correct = 0, 0\n",
    "#     for i, im_data in enumerate(test_loader):\n",
    "#         images, labels = im_data\n",
    "#         images = images.to(device)\n",
    "#         labels = labels.to(device)\n",
    "#         outputs = cnn(images)\n",
    "#         loss += loss_func(outputs, labels).item()\n",
    "#         _, pred = outputs.max(1)\n",
    "#         correct += torch.sum(pred == labels).item()\n",
    "# #         print('train correct', 100 * correct / batch_size)\n",
    "#         im = torchvision.utils.make_grid(images)\n",
    "#         writer.add_image('test im', im, global_step=step_test)\n",
    "#         step_test += 1\n",
    "# #         del images, labels\n",
    "# #         gc.collect()\n",
    "# #         torch.cuda.empty_cache()\n",
    "        \n",
    "#     correct /= len(test_data)\n",
    "#     loss /= len(test_data) // batch_size\n",
    "#     writer.add_scalar('test loss', loss, global_step=epoch + 1)\n",
    "#     writer.add_scalar('test correct', 100 * correct, global_step=epoch + 1)\n",
    "    \n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d110d8b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64613455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38a0108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52a6e99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263d0295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dfa95b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77323789",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
